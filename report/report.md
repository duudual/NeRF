# 基于 Transformer 的 NeRF：面向前向场景表示的探索

## 引言
神经辐射场（Neural Radiance Fields, NeRF）作为近年来具有里程碑意义的三维场景重建与渲染技术，凭借其对几何与外观的联合建模能力，能够在新视角上生成逼真图像。然而，经典 NeRF 的技术路线是“从场景出发的逆向优化”：给定多视角图像及相机参数，通过对大量空间位置和方向的体渲染积分进行采样，迭代训练一个记忆场景信息的多层感知机（MLP）。这种“场景专属”的优化流程带来显著计算成本与时间开销，限制了其在通用场景中的部署与广泛应用。

近年来的优化方案（如 Instant-NGP 的哈希格网表示）在速度与可扩展性上取得了重要进展，但本质上仍然依赖针对每个场景的训练。与之相对，我们提出沿着“前向（forward）预测”的技术路线进行探索：引入视觉变换器 VGGT（2025 年 CVPR 工作），其仅根据多视角图像即可直接预测点云、深度以及相机内外参等场景要素，体现了一种“从图像出发的场景理解”的前向范式。基于此，我们尝试让 VGGT 直接输出用于体渲染的表示，即：

- 方案一（直接预测 MLP）：由 VGGT 的特征经头部网络直接回归 NeRF 所需的 MLP 参数，使得渲染成为一次前向推断，无需对每个场景重复优化。
- 方案二（特征网格 + 通用小 MLP）：由 VGGT 先预测一个稠密或稀疏的特征网格，再接一个共享、浅层的小型 MLP，对坐标与朝向进行解码，完成体渲染。

这两种方案都体现了“正向获得场景表示”的思想。相比传统 NeRF 的逆向优化，前向路线具备三点潜在优势：（1）为“用 MLP 表示场景”的范式提供更可推广的生成途径；（2）借助语义特征与全局上下文，有利于匹配与语义理解；（3）VGGT 在单张照片上亦具备良好泛化，提升对稀疏视角的鲁棒性。更进一步，从表征角度看，用 MLP（或低维结构化潜变量）描述场景是一种有效的降维表示，有望成为通用三维感知与渲染的基础。

## Transformer‑NeRF（T‑nerf）项目方案
### 数据来源与总体设计
本项目以 NeRF‑MAE 的预训练数据为基础。这些数据以场景网格形式存储每个 3D 点的 RGB 与密度（sigma），可用于监督渲染输出或构造合成视角图像。

我们在 VGGT 框架上构建 T‑nerf：VGGT 可分为两部分——`aggregator` 与 `head`。前者通过 DINOv2 或 CNN 获取图像特征，并利用多视角注意力进行跨视角聚合；后者由不同任务的头部网络输出具体预测。基于该结构，我们新增一个 `NLPHead`，用于直接预测 NeRF 的 MLP 参数。

### 方案一：直接预测 MLP 参数
- 架构要点：冻结 VGGT 主体（尤其是 `aggregator`），仅训练 `NLPHead`。该头部以聚合后的多视角 token 为输入，回归一组 MLP 权重与偏置，以替换传统 NeRF 中场景专属、需长时优化得到的网络参数。
- 渲染与损失：在给定场景中，使用预测到的 MLP 对采样射线上的 3D 位置与方向进行前向计算，输出密度与颜色，并通过体渲染（体积积累与颜色合成）得到像素值；损失与经典 NeRF 设置一致，以重建误差（如 L2/PSNR）为主，可辅以正则（如权重范数）。
- 训练脚手架：训练流程与脚本在 T‑nerf 目录下组织，核心思路是“数据生成 → 多视角特征聚合 → `NLPHead` 参数回归 → 体渲染损失回传”，以端到端方式优化头部参数。

初步验证表明该方案具备可行性：当视角充足、场景统计与预训练分布一致时，`NLPHead` 能从多视角特征中提炼出用于体渲染的关键参数；在视角稀疏或分布偏移下，正则化与先验（例如结构化参数化）尤为重要。

（方案二：预测特征网格 + 通用小 MLP，因当前项目聚焦于方案一，本文不展开细节。）

## 动态 NeRF（Vanilla 版本）
动态场景的体渲染通常需要将时间参数 t 纳入表示与训练，使网络能够学习时变的几何与外观。传统做法是在网络结构与采样策略中显式加入时间维度并进行联合优化。受限于项目时间与算力，本工作对 Vanilla 动态方案先行略过，仅作为背景与对比基准。

## 动态 NeRF 的插值创新方案
基于 VGGT 的“先提特征、再解码”的工作流，我们受到动画关键帧插值的启发，提出一种新的动态生成方法：不直接在体渲染表示上建模时间，而是在特征空间进行插值，获得任意时刻的中间视图或潜在表示。

设输入为两个时刻 t0 与 t1 的多视角照片组，且两组之间一一对应，相机内外参一致。具体步骤如下：
1. 在 VGGT 的图像切片阶段（patch 分割并经 DINOv2 得到特征向量）之后进行插值。对 t0 的某一张照片中的一个 patch，在 t1 的该 patch 邻域内通过余弦相似度搜索最相似 patch。
2. 对两者特征向量做线性插值，并估计该 patch 在 t0→t1 之间任意时刻的 2D 位置与特征。
3. 依据估计的 2D 位置，采用双线性泼溅（bilinear splatting）将插值特征分配到最临近的四个 patch 网格点上；同时维护一个权重网格（Weight Grid），最终插值 token 需除以该权重进行归一化。
4. 若某些 patch 在特定时刻权重为 0，则在时间前半段以 t0 的对应 patch 填充、后半段以 t1 的对应 patch 填充，保证插值的稳定性与语义一致性。
5. 对所有 patch 完成处理后，得到在任意中间时刻 ti 的插值 token，再输入 VGGT 后续的注意力层与解码头部生成中间结果。

为提升效率，可缓存 t0 与 t1 的 patch 特征与匹配结果，在插值计算时直接读取。该方法在消耗上显著低于“带时间维的端到端训练”，且能够以更直观的方式获得时序中间状态。作为思路验证，我们先以点云输出为观察对象进行定性评估；实验现象表明，直接在 `aggregator` 的全局特征上插值时中间状态往往呈现“两个时刻的共存”，因此我们转向在 patch 层面插值以实现更细粒度、更局部一致的运动过渡。可以预见，若前述用于体渲染的表示（方案一或二）训练充分，该特征插值方案有望生成高质量的动态 NeRF 序列。

## 讨论与结论
本文探索了以 VGGT 为基础的前向场景表示路线：通过 `NLPHead` 直接预测 NeRF 的 MLP 参数（或替代性地预测特征网格并以小型共享 MLP 解码），以减少针对每个场景的长时优化，向“通用渲染器”迈进。同时，我们提出在特征空间进行关键帧插值的动态生成方案，避免显式建模时间维的高开销训练，为动态场景的高效生成提供了新的视角。

后续工作可沿两条路径深入：其一，结构化参数化与正则化（例如三平面表示、低秩约束）以增强前向预测的稳定性与泛化；其二，与哈希格网与即时渲染（Instant‑NGP）思路结合的“混合网格 + 小型 MLP”架构，进一步提升速度与质量。总体而言，前向获取体渲染表示的技术路线具有明确的潜力，值得在更大规模与更丰富场景上进行系统性验证。
