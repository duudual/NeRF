# 基于 Transformer 的 NeRF：面向前向场景表示的探索

## 引言
NeRF（Neural Radiance Fields）作为近年来具有里程碑意义的三维场景重建与渲染技术，凭借其对几何与外观的联合建模能力，能够实现逼真的图像渲染。然而，经典 NeRF 的技术路线是“从场景出发的逆向优化”：给定多视角图像及相机参数，通过对大量空间位置和方向的体渲染积分进行采样，迭代训练一个记忆场景信息的MLP。这种“场景专属”的优化流程带来显著计算成本与时间开销，限制了其在通用场景中的部署与广泛应用。

近年来的优化方案（如 Instant-NGP 的哈希格网表示）在速度与可扩展性上取得了重要进展，但本质上仍然依赖针对每个场景的训练。与之相对，我们提出沿着“前向（forward）预测”的技术路线进行探索：引入视觉变换器 VGGT（2025 CVPR best paper），其仅根据多视角图像即可直接预测点云、深度以及相机内外参等场景要素，展现出仅根据多视角图片识别出3D位置的能力，这是一种“从图像出发的场景理解”的前向范式。基于此，我们尝试让 VGGT 直接输出用于体渲染的表示，相比传统 NeRF 的逆向优化，前向路线具备三点潜在优势：（1）赋予NeRF泛化到不同场景的能力；（2）借助语义特征与全局上下文，有利于匹配与语义理解；（3）VGGT 在单张照片上亦具备良好泛化，提升对稀疏视角的鲁棒性。更进一步，我们甚至可以将用 MLP（或低维结构化潜变量）描述场景是=视为一种很好的对3D场景的表示形式，是一种有效的降维表示，如果我们的思路被验证可行，那么就能够实现由多视角图片正向获取此表征，是该3D场景的表示方法发挥实际作用的重要一环。

## Transformer‑NeRF（T‑nerf）项目方案
### 数据来源与总体设计
使用NeRF‑MAE 的预训练数据（https://huggingface.co/datasets/mirshad7/NeRF-MAE）。这些数据包含以场景网格形式存储每个 3D 点的 RGB 与密度（sigma）

VGGT 可分为两部分——`aggregator` 与 `head`。前者通过 DINOv2 或 CNN 获取图像特征，并利用注意力进行跨视角聚合；后者由不同任务的头部网络输出具体预测。基于该结构，我们新增一个 `NLPHead`，用于直接预测 NeRF 的 MLP 参数。

### 方案一：直接预测 MLP 参数
- 架构设计：冻结 VGGT的`aggregator`部分的参数，新增并训练 `NLPHead`。该头部以聚合后的多视角 token 为输入，预测一组 MLP 权重与偏置。
- 数据生成预处理：从场景的网格数据出发，首先设置合适的相机视角，使用体渲染技术获得多视角图片。
- 损失与优化：对于一个场景中，输入多视角图片到vggt中，使用NLPHead预测出一个MLP的参数，使用该MLP查询场景中的点的rgb与sigma取值，比较该点的实际RGB与sigma，计算损失

### 方案二：预测特征网格 + 通用小 MLP


## 动态 NeRF（Vanilla 版本）
动态场景的体渲染通常需要将时间参数 t 纳入表示与训练，使网络能够学习时变的几何与外观。传统做法是在网络结构与采样策略中显式加入时间维度并进行联合优化。受限于项目时间与算力，本工作对 Vanilla 动态方案先行略过，仅作为背景与对比基准。

## 动态 NeRF 的插值创新方案
受到动画关键帧插值的启发，提出一种全新的动态场景的生成方法：不直接在体渲染表示上建模时间，而是在特征空间进行插值，获得任意时刻的中间视图或潜在表示。

设输入为两个时刻 t0 与 t1 的多视角照片组，且两组之间一一对应，相机内外参一致。考虑t0~t1的任意时刻ti，具体步骤如下：
1. 在 VGGT 的aggregator对patch进行分割并经 DINOv2 得到特征向量之后，进行插值。对 t0 时刻的某一个 patch，在 t1 时刻的该 patch 11x11邻域内通过余弦相似度搜索最相似 patch。
2. 对这两个patch的特征向量利用ti做线性插值，同时根据对这两个Patch的2D位置进行插值获得ti时刻的patch位置，使用双线性泼溅的方式，将插值特征分配到最临近的四个 patch 网格点上，同时维护一个权重网格（Weight Grid），最终插值 token 需除以该权重进行归一化。
3. 对所有 patch 完成处理后，得到在任意中间时刻 ti 的插值 token，再输入 VGGT 后续的注意力层与解码头生成预测结果。

出于项目时间的限制，我们不得不并线进行任务，没时间利用我们预测体渲染信息的部分训练好后再执行动态场景的生成的尝试，所以我先尝试使用此插值融合技术，预测点云观察效果，作为该想法的可行性实验验证。实验发现，可以正确的预测出中间时刻的效果很好，可以预见的是，如果有一个能够预测良好的我们的模型，那么就可以实现很好的nerf版本的动态场景生成